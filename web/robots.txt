#
# robots.txt instruction file
#
# Robots.txt is a text file webmasters create to instruct web robots (typically search engine robots)
# how to crawl pages on their website.
# @since 1.0.0
#
# @author Danijel GaliÄ‡ <danijel.galic@outlook.com>
# @copyright 2023 FireHub Web Application Framework
# @license <https://opensource.org/licenses/OSL-3.0> OSL Open Source License version 3
#
# @package App\Web
#
# @version GIT: $Id$ Blob checksum.
#

User-agent: *
Disallow: